{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d6cf2d-6f79-4610-9590-64dd0558f884",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "## What is One-Hot Encoding?\n",
    "\n",
    "One-Hot Encoding is a method used to transform categorical data into a format that can be interpreted by machine learning algorithms. It is particularly useful when the data contains non-numerical or nominal categories that cannot be directly input into most ML algorithms, which expect numerical inputs.\n",
    "\n",
    "### Why Use One-Hot Encoding?\n",
    "\n",
    "1. **Prevent Misinterpretation of Data**: \n",
    "   - Machine learning models may assume an ordinal relationship if categories are represented as integers (e.g., `Red=1`, `Green=2`, `Blue=3`). One-hot encoding removes this risk by creating separate binary variables for each category.\n",
    "\n",
    "2. **Maintains Information**:\n",
    "   - Each category is represented uniquely, and the encoding does not imply any ranking or order.\n",
    "\n",
    "3. **Compatible with Many Models**:\n",
    "   - Many algorithms, such as linear regression, logistic regression, and neural networks, perform better with one-hot encoded data compared to raw categorical labels.\n",
    "\n",
    "---\n",
    "\n",
    "## How Does One-Hot Encoding Work?\n",
    "\n",
    "One-hot encoding converts a categorical feature into a set of binary features. Each unique category in the original feature is represented as a binary variable (column). If the category is present in a specific observation, the corresponding binary variable is marked as `1`, while all others are marked as `0`.\n",
    "\n",
    "### Example:\n",
    "\n",
    "#### Input Data:\n",
    "A dataset with a `Color` feature:\n",
    "| Index | Color  |\n",
    "|-------|--------|\n",
    "| 1     | Red    |\n",
    "| 2     | Green  |\n",
    "| 3     | Blue   |\n",
    "| 4     | Red    |\n",
    "\n",
    "#### One-Hot Encoded Data:\n",
    "| Index | Color_Red | Color_Green | Color_Blue |\n",
    "|-------|-----------|-------------|------------|\n",
    "| 1     | 1         | 0           | 0          |\n",
    "| 2     | 0         | 1           | 0          |\n",
    "| 3     | 0         | 0           | 1          |\n",
    "| 4     | 1         | 0           | 0          |\n",
    "\n",
    "---\n",
    "\n",
    "## Benefits of One-Hot Encoding\n",
    "\n",
    "1. **Prevents Ordinal Bias**:\n",
    "   - One-hot encoding ensures that no ordinal relationships are implied between categories, as all categories are treated as independent binary features.\n",
    "\n",
    "2. **Works Well with Numerical Models**:\n",
    "   - Algorithms that rely on numerical data (e.g., linear regression, neural networks) can effectively process one-hot encoded features.\n",
    "\n",
    "3. **Simplicity**:\n",
    "   - Easy to implement using libraries like `pandas` or `scikit-learn`.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations of One-Hot Encoding\n",
    "\n",
    "1. **Curse of Dimensionality**:\n",
    "   - If the categorical feature has many unique values (e.g., countries, product IDs), one-hot encoding can create a very large number of binary columns, increasing memory and computational requirements.\n",
    "\n",
    "2. **Sparse Representation**:\n",
    "   - The resulting encoded matrix is sparse (contains many zeros), which can lead to inefficiencies in storage and computation.\n",
    "\n",
    "3. **Overfitting Risk**:\n",
    "   - High dimensionality may lead to overfitting in some models, especially when the dataset is small.\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Use Cases\n",
    "\n",
    "One-hot encoding is widely used in the following scenarios:\n",
    "1. **Nominal Data**: Non-ordered categories like `Gender`, `Colors`, `Animal types`, etc.\n",
    "2. **Feature Engineering**: Transforming text or categorical data for use in ML algorithms.\n",
    "3. **Text Classification**: Encoding bag-of-words or tokenized features.\n",
    "\n",
    "---\n",
    "\n",
    "## Advanced Considerations\n",
    "\n",
    "### Alternatives to One-Hot Encoding:\n",
    "1. **Label Encoding**:\n",
    "   - Assigns unique integers to each category. Used when there is an ordinal relationship.\n",
    "   - Example: `Low=1`, `Medium=2`, `High=3`.\n",
    "\n",
    "2. **Binary Encoding**:\n",
    "   - Encodes categories as binary digits, which reduces dimensionality compared to one-hot encoding.\n",
    "   - Example:\n",
    "     - `1` → `01`\n",
    "     - `2` → `10`\n",
    "     - `3` → `11`\n",
    "\n",
    "3. **Target Encoding**:\n",
    "   - Encodes categories based on the mean of the target variable for each category.\n",
    "\n",
    "4. **Frequency Encoding**:\n",
    "   - Encodes categories based on their frequency in the dataset.\n",
    "\n",
    "### Handling High Cardinality:\n",
    "- For features with many unique values (e.g., `Zip Codes`), one-hot encoding may result in too many columns. Possible solutions include:\n",
    "  - Grouping categories into broader categories.\n",
    "  - Using embedding layers in deep learning.\n",
    "  - Applying dimensionality reduction techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation in Python\n",
    "\n",
    "### Using `pandas`\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Red']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoded_df = pd.get_dummies(df, columns=['Color'])\n",
    "\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e00dd-cd40-4652-abc7-e368ba8c0a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
